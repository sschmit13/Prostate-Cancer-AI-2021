{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9584026-8b5e-4c74-ac13-f21c3edb27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outline for Prostate Cancer Surgical Margin NN \n",
    "\n",
    "#1. ModelA = MLP that predicts surgical margin status based on tabular data from REDCap database\n",
    "#1a. Load and pre-process the data\n",
    "#1b. Construct the neural network arhcitecture with a new class\n",
    "#1c. Set hyperparameters and run training and testing loops to opitmize parameters. Save with model.state_dict \n",
    "\n",
    "#2. ModelB = a Densenet that predicts surgical margin status (+ or -) based on pre-op MRI images\n",
    "#2a. Create a \"custom image dataset\" with image files, pull out margin status \"labels\" from a corresponding csv file (refer to lightning tutorial for help)\n",
    "#2b. Construct the architecture of the Densenet with a new class \n",
    "#2c. Set hyperparameters and run training and testing loops to opitmize parameters. Save with model.state_dict \n",
    "\n",
    "#3. Ensemble Network = model A + model B\n",
    "#3a. new Ensemble class that subclasses nn.module, include one linear layer that takes as input 2 and gives output 1 (concatenation of A and B will make the input need to be 2, we want output to be 4)\n",
    "    #-->in forward method, pass x1 thru A, x2 thru B, then use torch.cat(A output, B output) dim=1, then pass thru linear layer and add nonlinearity \n",
    "#3b. create new model instances and load state_dicts, then create an instance of Ensemble model \n",
    "#3c. Set hyperparameters and run training and testing loops to opitmize parameters ?\n",
    "\n",
    "#4. Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "240ac03e-8662-4dee-860f-dbe6929ae5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c1d8761-eeee-4a80-a2f9-95018c44db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.), tensor([28.0000,  0.0000,  0.0000,  4.0000, 22.0000,  5.5000,  7.0000, 53.0000]))\n"
     ]
    }
   ],
   "source": [
    "#1a and #2a â€” getting the datasets ready (redcap_file has tabular data, annotations_file has the labels, img_dir holds the MRI's)\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, redcap_file = None, annotations_file = None, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, header=0, index_col='record_id') #default header=0\n",
    "        self.tabular = pd.read_csv(redcap_file, header=0)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):      \n",
    "        x = self.tabular.iloc[idx, 0] #finds relevant record ID \n",
    "        label = self.img_labels.loc[x, 'margins_positive'] #link record ID to margin label in separate csv\n",
    "        \n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.from_numpy(np.array(label)).float()                \n",
    "\n",
    "        tabular = self.tabular.iloc[idx, 1:] #tabular data starts in second column of csv (after ID's)\n",
    "        tabular = tabular.tolist()\n",
    "        tabular = torch.from_numpy(np.array(tabular)).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            tabular = self.transform(tabular)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return label, tabular  \n",
    "\n",
    "    \n",
    "my_redcap_file = '/Users/Stephen_Schmit/Documents/SC-BMI/De-identified data/final_finalredcap_dataframe.csv'\n",
    "my_annotations_file = '/Users/Stephen_Schmit/Documents/SC-BMI/De-identified data/final_cleanlabels_dataframe.csv'\n",
    "\n",
    "\n",
    "tabular_data = TabularDataset(redcap_file = my_redcap_file, annotations_file = my_annotations_file, transform = None, target_transform=None)\n",
    "\n",
    "print(tabular_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d377a02-b28f-422a-ab23-edf33ea48a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hperparameters for 1a\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "#dataloaders for 1a, 1767 samples total\n",
    "train_set, test_set = torch.utils.data.random_split(tabular_data, [1467, 300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58c5a9a7-d90e-40ad-b241-66b09bb053a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights should be defined as the inverse class frequency defined for each sample\n",
    "train_targets = [] #empty list of all the labels in the train set \n",
    "test_targets = []\n",
    "\n",
    "for target, tabular in train_set: #for loop to fill list with all the label tensors\n",
    "    target = int(target)\n",
    "    train_targets.append(target)\n",
    "    \n",
    "for target, tabular in test_set: #for loop to fill list with all the label tensors\n",
    "    target = int(target)\n",
    "    test_targets.append(target)\n",
    "\n",
    "_, train_class_counts = np.unique(train_targets, return_counts=True)\n",
    "_, test_class_counts = np.unique(test_targets, return_counts=True)\n",
    "\n",
    "train_weights = 1. / torch.tensor(train_class_counts, dtype=torch.float) #tensor of class counts, then reciprocal in same format \n",
    "test_weights = 1. / torch.tensor(test_class_counts, dtype=torch.float)\n",
    "\n",
    "train_weights = train_weights[train_targets] # indexes weights tensor to get corresponding weight for each target\n",
    "test_weights = test_weights[test_targets]\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=train_weights, num_samples=len(train_weights), replacement=True)\n",
    "test_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=test_weights, num_samples=len(test_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "65e52622-4b68-445a-8515-b59f15339ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: torch.Size([50, 8])\n",
      "Labels batch shape: torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "#Dataloader class makes the train/test sets iterable and defines batch size\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "# check batch sizes...they look correct\n",
    "train_labels, train_features = next(iter(train_loader))\n",
    "print(f\"Features batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f8980439-9156-426a-a92e-53874642f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMLP(\n",
      "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (ReLU): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#1c. will need to change input size to correspond with number of tabular data fields\n",
    "\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(8,16)\n",
    "        self.fc2 = nn.Linear(16,1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "    \n",
    "    def get_weights(self):        #not sure what this does but from a tutorial on binary classification\n",
    "        return self.weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ReLU(out)\n",
    "        out = torch.sigmoid(self.fc2(out)) #sigmoid needed bc using BCELoss\n",
    "        return out\n",
    "    \n",
    "modelA = MyMLP()\n",
    "print(modelA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a5d19d71-e41a-460e-a304-b0c21c6faca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double checking things\n",
    "\n",
    "# for batch, (label, tabular) in enumerate(train_loader):\n",
    "#     print(tabular)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6d13e262-8fa1-4e90-9340-909e08d39e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(modelA.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "#TRAINING THE NETWORK\n",
    "def train(model, train_loader, optimizer, device=None):\n",
    "    modelA.train()\n",
    "    y_true = []\n",
    "    y_pred = []    \n",
    "    for i in train_loader:\n",
    "        \n",
    "        #LOADING THE DATA IN A BATCH\n",
    "        target, data = i\n",
    " \n",
    "        #MOVING THE TENSORS TO THE CONFIGURED DEVICE, might need to do later when I have images\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "       \n",
    "        #FORWARD PASS\n",
    "        output = modelA(data.float())\n",
    "        loss = loss_fn(output, target.unsqueeze(1)) \n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # PREDICTIONS \n",
    "        pred = np.round(output.detach())\n",
    "        target = np.round(target.detach())\n",
    "        y_pred.extend(pred.tolist())\n",
    "        y_true.extend(target.tolist())\n",
    "        \n",
    "    print('Accuracy on training set is' , accuracy_score(y_true, y_pred)) #this function from sklearn, calculates num correct/total from the 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4a613981-21bc-4669-a265-8f90883a4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE MODEL\n",
    "def test(model, test_loader, device=None):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            target,data = i\n",
    "            \n",
    "            # moving the tensors to the configured device\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # the model on the data\n",
    "            output = model(data.float())\n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(output) #rounds output to 0 decimals, so if ouptut is 0.6, predicts surgical margin positive\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "    \n",
    "            \n",
    "    print('Accuracy on test set is' , accuracy_score(y_true, y_pred))\n",
    "    print('**************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "45d70dcb-f168-48c2-a9fb-4d78746e550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set is 0.4942058623040218\n",
      "Accuracy on test set is 0.5733333333333334\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5214723926380368\n",
      "Accuracy on test set is 0.52\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5426039536468984\n",
      "Accuracy on test set is 0.48\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5337423312883436\n",
      "Accuracy on test set is 0.5333333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5541922290388548\n",
      "Accuracy on test set is 0.5033333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5487389229720518\n",
      "Accuracy on test set is 0.5066666666666667\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5664621676891616\n",
      "Accuracy on test set is 0.6066666666666667\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5487389229720518\n",
      "Accuracy on test set is 0.5233333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5705521472392638\n",
      "Accuracy on test set is 0.5366666666666666\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.558282208588957\n",
      "Accuracy on test set is 0.5533333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5589638718473074\n",
      "Accuracy on test set is 0.5166666666666667\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5480572597137015\n",
      "Accuracy on test set is 0.5166666666666667\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5555555555555556\n",
      "Accuracy on test set is 0.5333333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5364689843217451\n",
      "Accuracy on test set is 0.5366666666666666\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5555555555555556\n",
      "Accuracy on test set is 0.38333333333333336\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5603271983640081\n",
      "Accuracy on test set is 0.56\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5405589638718473\n",
      "Accuracy on test set is 0.5233333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5610088616223585\n",
      "Accuracy on test set is 0.5433333333333333\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5139740967961827\n",
      "Accuracy on test set is 0.54\n",
      "**************************************************************************\n",
      "Accuracy on training set is 0.5548738922972052\n",
      "Accuracy on test set is 0.49\n",
      "**************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(model=modelA, train_loader=train_loader, optimizer=optimizer)\n",
    "    test(model=modelA, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "701738ce-387f-4514-8bc3-96e6aebd871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyMLP(\n",
       "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (ReLU): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model parameters and weights \n",
    "\n",
    "import torchvision.models as models\n",
    "torch.save(modelA.state_dict(), '/Users/Stephen_Schmit/Documents/SC-BMI/p_eickhoff_sc2021/modelA_weights')\n",
    "modelA.eval() #sets model to evaluation mode instead of training\n",
    "\n",
    "# use below code to load later\n",
    "# modelA = MyMLP(*args, **kwargs)\n",
    "# modelA.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f238ddb6-50e1-4dfd-9452-192e7e5dccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of code for tabular dataâ€”below work on densenet once tabular figured out\n",
    "# below is me experimenting from a different tutorial...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e681c-0759-4206-8ef4-6af58fbb8f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553f9e3-515f-4bc6-ae71-76600f916bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198652e-b827-4a7d-9471-aa7c22b86e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad73aef-bff0-4063-99a8-169de32de439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a2933-7669-4f19-8e01-45c90c69a0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858c7f7-29ff-4460-8df6-47d244c508fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9507414-c82b-4768-9b20-a7a99796d9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.967291  [    0/ 1475]\n",
      "loss: 0.608459  [  400/ 1475]\n",
      "loss: 0.580153  [  800/ 1475]\n",
      "loss: 0.372025  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.025881 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.538290  [    0/ 1475]\n",
      "loss: 0.615304  [  400/ 1475]\n",
      "loss: 0.589737  [  800/ 1475]\n",
      "loss: 0.457458  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.025070 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.493684  [    0/ 1475]\n",
      "loss: 0.469736  [  400/ 1475]\n",
      "loss: 0.609630  [  800/ 1475]\n",
      "loss: 0.715592  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.024853 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.479104  [    0/ 1475]\n",
      "loss: 0.353151  [  400/ 1475]\n",
      "loss: 0.628308  [  800/ 1475]\n",
      "loss: 0.625308  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.025433 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.652548  [    0/ 1475]\n",
      "loss: 0.523565  [  400/ 1475]\n",
      "loss: 0.552751  [  800/ 1475]\n",
      "loss: 0.490231  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.025037 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.672082  [    0/ 1475]\n",
      "loss: 0.435895  [  400/ 1475]\n",
      "loss: 0.553438  [  800/ 1475]\n",
      "loss: 0.629991  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.024817 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.430068  [    0/ 1475]\n",
      "loss: 0.565830  [  400/ 1475]\n",
      "loss: 0.694117  [  800/ 1475]\n",
      "loss: 0.387751  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.024942 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.661774  [    0/ 1475]\n",
      "loss: 0.731225  [  400/ 1475]\n",
      "loss: 0.368025  [  800/ 1475]\n",
      "loss: 0.514340  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.025996 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.479203  [    0/ 1475]\n",
      "loss: 0.432935  [  400/ 1475]\n",
      "loss: 0.507070  [  800/ 1475]\n",
      "loss: 0.395939  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.024701 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.483201  [    0/ 1475]\n",
      "loss: 0.510764  [  400/ 1475]\n",
      "loss: 0.399442  [  800/ 1475]\n",
      "loss: 0.373191  [ 1200/ 1475]\n",
      "Test Error: \n",
      " Accuracy: 1620.0%, Avg loss: 0.025255 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#1c. continued\n",
    "optimizer = torch.optim.SGD(modelA.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "\n",
    "#define the train and test loops\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (label, tabular) in enumerate(dataloader):        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(tabular)\n",
    "        label = torch.unsqueeze(label, 1) #gets the target size to be the same as the models' output size [1,1] because batch size is 1 and then returns one prediction each batch\n",
    "        loss = loss_fn(pred, label) \n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()  #sets gradients of all optimized torch tensors to 0\n",
    "        loss.backward()   #READ THIS\n",
    "                          #The change in the loss for a small change in an input weight is the gradient of that weight and is calculated using backpropagation\n",
    "                         #backpropagation is kicked off when we call .backward() on the error tensor (thus loss.backward() written here). \n",
    "                        #Autograd then calculates and stores the gradients for each model parameter in the parameterâ€™s .grad attribute.\n",
    "        optimizer.step() #Finally, we call .step() to initiate gradient descent. The optimizer adjusts each parameter by its gradient stored in .grad\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), batch * len(tabular)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, tabular in dataloader:\n",
    "            pred = model(tabular.float())\n",
    "            label = torch.unsqueeze(label, 1)\n",
    "            test_loss += loss_fn(pred, label).item() #compares the label (y) with the prediction based on loss fn defined above\n",
    "            correct += (pred.argmax(1) == label).type(torch.float).sum().item()  #why is \"1\" an argument of argmax?\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, modelA, loss_fn, optimizer)\n",
    "    test_loop(test_loader, modelA, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2af3b-b833-421a-aace-bee9662b7363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89e1d3-1c26-43dc-b732-681292cd79d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b052aa6-0617-4c10-94f3-b994d7fc0482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ad513-a050-479b-a6f9-a481862d0291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9452ec5-b374-435b-98c0-4d835e342935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7566ee-7ed7-4cde-9ea5-435749fcb1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab7ae7-e5a1-418f-b696-d90b0845955f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f40ba-2b92-42e0-91ef-347c39cee618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199c81d-1e41-43df-9b4b-d7e1cb515611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d5ecca9-4c12-43d7-9645-1c9487653167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/Stephen_Schmit/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-082a44f0d58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#preprocess the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m preprocess = transforms.Compose([\n\u001b[1;32m     15\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "#2b. ??????? need to figure out the densenet. Do we want pretrained? Also, this doesnt look anything like last tutorial.\n",
    "#where are the train and test loops? In this example how does the model know the label?\n",
    "\n",
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.9.0', 'densenet121', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.9.0', 'densenet169', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.9.0', 'densenet201', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.9.0', 'densenet161', pretrained=True)\n",
    "\n",
    "\n",
    "#preprocess the images\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2598b2-09ad-4e8d-a08c-f07e4221b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2c. continued, actually running the training now \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() #loss_fn defined as cross entropy loss because this is the best function in classication tasks\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
